{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": " CGAN on CiFAR-10",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zornTang/NeutraPro/blob/main/CGAN_on_CiFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T13:44:50.148247Z",
          "iopub.execute_input": "2024-08-26T13:44:50.148645Z",
          "iopub.status.idle": "2024-08-26T13:45:02.973552Z",
          "shell.execute_reply.started": "2024-08-26T13:44:50.148578Z",
          "shell.execute_reply": "2024-08-26T13:45:02.972771Z"
        },
        "trusted": true,
        "id": "gbTnRDzbGhIr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the dataset, we will first declare some global variables\n",
        "batch_size = 16\n",
        "epoch_count = 50\n",
        "noise_dim = 100\n",
        "n_class = 10\n",
        "tags = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "img_size = 32\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, y_train), (_, _) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "X_train = (X_train - 127.5) / 127.5\n",
        "\n",
        "# Create tf.data.Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T13:45:12.991944Z",
          "iopub.execute_input": "2024-08-26T13:45:12.993149Z",
          "iopub.status.idle": "2024-08-26T13:45:30.633223Z",
          "shell.execute_reply.started": "2024-08-26T13:45:12.993095Z",
          "shell.execute_reply": "2024-08-26T13:45:30.632437Z"
        },
        "trusted": true,
        "id": "LjzePs8rGhIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting a random image from the dataset\n",
        "plt.figure(figsize=(2,2))\n",
        "idx = np.random.randint(0,len(X_train))\n",
        "img = image.array_to_img(X_train[idx], scale=True)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(tags[y_train[idx][0]])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T13:46:00.887481Z",
          "iopub.execute_input": "2024-08-26T13:46:00.888372Z",
          "iopub.status.idle": "2024-08-26T13:46:01.041614Z",
          "shell.execute_reply.started": "2024-08-26T13:46:00.888331Z",
          "shell.execute_reply": "2024-08-26T13:46:01.04038Z"
        },
        "trusted": true,
        "id": "4K8E4Gq1GhIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss function for Classification between Real and Fake\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Discriminator Loss\n",
        "def discriminator_loss(real, fake):\n",
        "\treal_loss = bce_loss(tf.ones_like(real), real)\n",
        "\tfake_loss = bce_loss(tf.zeros_like(fake), fake)\n",
        "\ttotal_loss = real_loss + fake_loss\n",
        "\treturn total_loss\n",
        "\n",
        "# Generator Loss\n",
        "def generator_loss(preds):\n",
        "\treturn bce_loss(tf.ones_like(preds), preds)\n",
        "\n",
        "# Optimiser for both Generator and Dsicriminator\n",
        "d_optimizer=Adam(learning_rate=0.0002, beta_1 = 0.5)\n",
        "g_optimizer=Adam(learning_rate=0.0002, beta_1 = 0.5)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T13:48:30.588914Z",
          "iopub.execute_input": "2024-08-26T13:48:30.589657Z",
          "iopub.status.idle": "2024-08-26T13:48:30.607457Z",
          "shell.execute_reply.started": "2024-08-26T13:48:30.589605Z",
          "shell.execute_reply": "2024-08-26T13:48:30.606221Z"
        },
        "trusted": true,
        "id": "_caD-V7BGhIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "# label input\n",
        "\tin_label = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "\t# create an embedding layer for all the 10 classes in the form of a vector\n",
        "\t# of size 50\n",
        "\tli = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
        "\n",
        "\tn_nodes = 8 * 8\n",
        "\tli = tf.keras.layers.Dense(n_nodes)(li)\n",
        "\t# reshape the layer\n",
        "\tli = tf.keras.layers.Reshape((8, 8, 1))(li)\n",
        "\n",
        "\t# image generator input\n",
        "\tin_lat = tf.keras.layers.Input(shape=(noise_dim,))\n",
        "\n",
        "\tn_nodes = 128 * 8 * 8\n",
        "\tgen = tf.keras.layers.Dense(n_nodes)(in_lat)\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\tgen = tf.keras.layers.Reshape((8, 8, 128))(gen)\n",
        "\n",
        "\t# merge image gen and label input\n",
        "\tmerge = tf.keras.layers.Concatenate()([gen, li])\n",
        "\n",
        "\tgen = tf.keras.layers.Conv2DTranspose(\n",
        "\t\t128, (4, 4), strides=(2, 2), padding='same')(merge) # 16x16x128\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "\tgen = tf.keras.layers.Conv2DTranspose(\n",
        "\t\t128, (4, 4), strides=(2, 2), padding='same')(gen) # 32x32x128\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "\tout_layer = tf.keras.layers.Conv2D(\n",
        "\t\t3, (8, 8), activation='tanh', padding='same')(gen) # 32x32x3\n",
        "\n",
        "\tmodel = Model([in_lat, in_label], out_layer)\n",
        "\treturn model\n",
        "\n",
        "\n",
        "g_model = build_generator()\n",
        "g_model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T13:50:32.282955Z",
          "iopub.execute_input": "2024-08-26T13:50:32.283629Z",
          "iopub.status.idle": "2024-08-26T13:50:32.417865Z",
          "shell.execute_reply.started": "2024-08-26T13:50:32.283579Z",
          "shell.execute_reply": "2024-08-26T13:50:32.417043Z"
        },
        "trusted": true,
        "id": "AQrqDj0zGhIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "# label input\n",
        "    in_label = tf.keras.layers.Input(shape=(1,))\n",
        "#This vector of size 50 will be learnt by the discriminator\n",
        "    li = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
        "\n",
        "    n_nodes = img_size * img_size\n",
        "    li = tf.keras.layers.Dense(n_nodes)(li)\n",
        "\n",
        "    li = tf.keras.layers.Reshape((img_size, img_size, 1))(li)\n",
        "\n",
        "\n",
        "# image input\n",
        "    in_image = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
        "\n",
        "    merge = tf.keras.layers.Concatenate()([in_image, li])\n",
        "\n",
        "\n",
        "#We will combine input label with input image and supply as inputs to the model.\n",
        "    fe = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "    fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "    fe = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "    fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "    fe = tf.keras.layers.Flatten()(fe)\n",
        "\n",
        "    fe = tf.keras.layers.Dropout(0.4)(fe)\n",
        "\n",
        "    out_layer = tf.keras.layers.Dense(1, activation='sigmoid')(fe)\n",
        "\n",
        "# define model the model.\n",
        "    model = Model([in_image, in_label], out_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "d_model = build_discriminator()\n",
        "d_model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T14:00:15.50735Z",
          "iopub.execute_input": "2024-08-26T14:00:15.507733Z",
          "iopub.status.idle": "2024-08-26T14:00:15.597373Z",
          "shell.execute_reply.started": "2024-08-26T14:00:15.507699Z",
          "shell.execute_reply": "2024-08-26T14:00:15.596504Z"
        },
        "trusted": true,
        "id": "G1p5246zGhIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the train_step function into a callable TensorFlow graph\n",
        "@tf.function\n",
        "def train_step(dataset):\n",
        "\n",
        "\treal_images, real_labels = dataset\n",
        "\t# Sample random points in the latent space and concatenate the labels.\n",
        "\trandom_latent_vectors = tf.random.normal(shape=(batch_size, noise_dim))\n",
        "\tgenerated_images = g_model([random_latent_vectors, real_labels])\n",
        "\n",
        "\t# Train the discriminator.\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\tpred_fake = d_model([generated_images, real_labels])\n",
        "\t\tpred_real = d_model([real_images, real_labels])\n",
        "\n",
        "\t\td_loss = discriminator_loss(pred_real, pred_fake)\n",
        "\n",
        "\tgrads = tape.gradient(d_loss, d_model.trainable_variables)\n",
        "\t# print(grads)\n",
        "\td_optimizer.apply_gradients(zip(grads, d_model.trainable_variables))\n",
        "\n",
        "\t#-----------------------------------------------------------------#\n",
        "\n",
        "\t# Sample random points in the latent space.\n",
        "\trandom_latent_vectors = tf.random.normal(shape=(batch_size, noise_dim))\n",
        "\n",
        "\t# Train the generator\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\tfake_images = g_model([random_latent_vectors, real_labels])\n",
        "\t\tpredictions = d_model([fake_images, real_labels])\n",
        "\t\tg_loss = generator_loss(predictions)\n",
        "\n",
        "\tgrads = tape.gradient(g_loss, g_model.trainable_variables)\n",
        "\tg_optimizer.apply_gradients(zip(grads, g_model.trainable_variables))\n",
        "\n",
        "\treturn d_loss, g_loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T14:01:09.900254Z",
          "iopub.execute_input": "2024-08-26T14:01:09.90066Z",
          "iopub.status.idle": "2024-08-26T14:01:09.909752Z",
          "shell.execute_reply.started": "2024-08-26T14:01:09.900611Z",
          "shell.execute_reply": "2024-08-26T14:01:09.908936Z"
        },
        "trusted": true,
        "id": "Jy-qdD5oGhIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_samples(num_samples, n_class, g_model):\n",
        "    fig, axes = plt.subplots(10, num_samples, figsize=(10, 20))\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(wspace=None, hspace=0.2)\n",
        "\n",
        "    for l in np.arange(10):\n",
        "        random_noise = tf.random.normal(shape=(num_samples, noise_dim))\n",
        "        label = tf.ones(num_samples) * l\n",
        "        gen_imgs = g_model.predict([random_noise, label])\n",
        "        for j in range(gen_imgs.shape[0]):\n",
        "            img = image.array_to_img(gen_imgs[j], scale=True)\n",
        "            axes[l, j].imshow(img)\n",
        "            axes[l, j].yaxis.set_ticks([])\n",
        "            axes[l, j].xaxis.set_ticks([])\n",
        "\n",
        "            if j == 0:\n",
        "                axes[l, j].set_ylabel(tags[l])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T14:04:50.011555Z",
          "iopub.execute_input": "2024-08-26T14:04:50.012261Z",
          "iopub.status.idle": "2024-08-26T14:04:50.020055Z",
          "shell.execute_reply.started": "2024-08-26T14:04:50.012221Z",
          "shell.execute_reply": "2024-08-26T14:04:50.019055Z"
        },
        "trusted": true,
        "id": "BDduAZMDGhIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs=epoch_count):\n",
        "\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tprint('Epoch: ', epochs)\n",
        "\t\td_loss_list = []\n",
        "\t\tg_loss_list = []\n",
        "\t\tq_loss_list = []\n",
        "\t\tstart = time.time()\n",
        "\n",
        "\t\titern = 0\n",
        "\t\tfor image_batch in tqdm(dataset):\n",
        "\t\t\td_loss, g_loss = train_step(image_batch)\n",
        "\t\t\td_loss_list.append(d_loss)\n",
        "\t\t\tg_loss_list.append(g_loss)\n",
        "\t\t\titern=itern+1\n",
        "\n",
        "\t\tshow_samples(3, n_class, g_model)\n",
        "\n",
        "\t\tprint (f'Epoch: {epoch} -- Generator Loss: {np.mean(g_loss_list)}, Discriminator Loss: {np.mean(d_loss_list)}\\n')\n",
        "\t\tprint (f'Took {time.time()-start} seconds. \\n\\n')\n",
        "\n",
        "\n",
        "train(dataset, epochs=epoch_count)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-26T14:05:22.602872Z",
          "iopub.execute_input": "2024-08-26T14:05:22.603254Z"
        },
        "trusted": true,
        "id": "JRs11NfNGhIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjdnPy1nGhIv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}